"""
çŸ­å›å¤AIç”Ÿæˆå™¨
æ”¯æŒ1-10å­—çš„æ™ºèƒ½çŸ­å›å¤ç”Ÿæˆï¼Œé›†æˆnew-apié¡¹ç›®
"""

import openai
import random
import asyncio
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime

from .content_analyzer import ContentAnalyzer, ContentAnalysis
from ..config.config_manager import AIConfig


@dataclass
class ShortReplyConfig:
    """çŸ­å›å¤é…ç½®"""
    api_key: str
    base_url: str = "http://localhost:3000/v1"  # new-apié¡¹ç›®é»˜è®¤åœ°å€
    model: str = "gpt-3.5-turbo"
    max_length: int = 10
    min_length: int = 1
    temperature: float = 0.8
    max_tokens: int = 30


class ShortReplyGenerator:
    """çŸ­å›å¤ç”Ÿæˆå™¨"""
    
    def __init__(self, config: ShortReplyConfig):
        self.config = config
        self.content_analyzer = ContentAnalyzer()
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨new-apié¡¹ç›®
        self.client = openai.AsyncOpenAI(
            api_key=config.api_key,
            base_url=config.base_url
        )
        
        # é¢„å®šä¹‰çŸ­å›å¤æ¨¡æ¿åº“ï¼ˆä¼˜åŒ–ï¼‰
        self.reply_templates = {
            "æ±‚åŠ©é—®ç­”": {
                "positive": ["è¯•è¯•çœ‹", "å¯ä»¥çš„", "æœ‰ç”¨", "æ²¡é—®é¢˜", "ğŸ‘"],
                "negative": ["åŠ æ²¹", "è¯•è¯•çœ‹", "æ£€æŸ¥ä¸‹", "åˆ«æ€¥", "ä¼šå¥½çš„"],
                "neutral": ["è¯•è¯•çœ‹", "å¯ä»¥çš„", "æ”¯æŒ", "ğŸ‘"]
            },
            "æŠ€æœ¯è®¨è®º": {
                "positive": ["èµåŒ", "æœ‰é“ç†", "å­¦ä¹ äº†", "ä¸é”™", "ğŸ‘"],
                "negative": ["è¯•è¯•çœ‹", "æ£€æŸ¥ä¸‹", "è°ƒè¯•ä¸‹", "ğŸ‘"],
                "neutral": ["å­¦ä¹ äº†", "æœ‰é“ç†", "æ”¶è—", "ğŸ‘"]
            },
            "ç”Ÿæ´»åˆ†äº«": {
                "positive": ["æœ‰æ„æ€", "èµ", "åŒæ„Ÿ", "ä¸é”™", "ğŸ‘"],
                "negative": ["ç†è§£", "åŠ æ²¹", "ä¼šå¥½çš„", "æ”¯æŒ"],
                "neutral": ["æœ‰æ„æ€", "èµ", "åŒæ„Ÿ", "ğŸ‘"]
            },
            "è®¨è®ºäº¤æµ": {
                "positive": ["åŒæ„", "æœ‰é“ç†", "æ”¯æŒ", "ğŸ‘"],
                "negative": ["ç†è§£", "æœ‰é“ç†", "æ”¯æŒ", "ğŸ‘"],
                "neutral": ["åŒæ„", "æœ‰é“ç†", "æ”¯æŒ", "ğŸ‘"]
            },
            "æ–°é—»èµ„è®¯": {
                "positive": ["å…³æ³¨", "æ”¶è—", "æœ‰ç”¨", "ğŸ‘"],
                "negative": ["å…³æ³¨", "äº†è§£", "ğŸ‘"],
                "neutral": ["å…³æ³¨", "æ”¶è—", "ğŸ‘"]
            },
            "èµ„æºåˆ†äº«": {
                "positive": ["æ„Ÿè°¢", "æ”¶è—", "æœ‰ç”¨", "ğŸ‘"],
                "negative": ["æ„Ÿè°¢", "æ”¶è—", "ğŸ‘"],
                "neutral": ["æ„Ÿè°¢", "æ”¶è—", "ğŸ‘"]
            },
            "é€šç”¨": {
                "positive": ["ğŸ‘", "èµ", "ä¸é”™", "æ”¯æŒ"],
                "negative": ["åŠ æ²¹", "æ”¯æŒ", "ğŸ‘"],
                "neutral": ["ğŸ‘", "æ”¯æŒ", "ä¸é”™"]
            }
        }
        
        # æƒ…æ„Ÿå›å¤æ˜ å°„
        self.sentiment_replies = {
            "positive": ["èµ", "ğŸ‘", "ä¸é”™", "æ”¯æŒ", "å¾ˆæ£’", "å‰å®³"],
            "negative": ["åŠ æ²¹", "ç†è§£", "æ”¯æŒ", "æ²¡äº‹çš„", "ä¼šå¥½çš„"],
            "neutral": ["äº†è§£", "æ”¶è—", "å­¦ä¹ äº†", "æ„Ÿè°¢", "ğŸ‘"]
        }
        
        # ç¦ç”¨è¯åˆ—è¡¨
        self.banned_words = ["AI", "æœºå™¨äºº", "ç®—æ³•", "ç”Ÿæˆ", "è‡ªåŠ¨", "äººå·¥æ™ºèƒ½"]
        
        # å›å¤å†å²ï¼ˆç”¨äºé¿å…é‡å¤ï¼‰
        self.recent_replies = []
        self.max_history = 20
    
    async def generate_reply(self, post_title: str, post_content: str) -> str:
        """ç”ŸæˆçŸ­å›å¤"""
        try:
            # åˆ†æå†…å®¹
            analysis = self.content_analyzer.analyze(post_title, post_content)
            
            # é¦–å…ˆå°è¯•AIç”Ÿæˆ
            ai_reply = await self._generate_ai_reply(post_title, post_content, analysis)
            
            if ai_reply and self._validate_reply(ai_reply):
                # æ£€æŸ¥é‡å¤æ€§
                if not self._is_duplicate(ai_reply):
                    self._add_to_history(ai_reply)
                    return ai_reply
            
            # AIç”Ÿæˆå¤±è´¥æˆ–é‡å¤ï¼Œä½¿ç”¨æ¨¡æ¿å›å¤
            template_reply = self._generate_template_reply(analysis)
            self._add_to_history(template_reply)
            return template_reply
            
        except Exception as e:
            print(f"å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            # æœ€ç»ˆé™çº§æ–¹æ¡ˆ
            fallback_reply = random.choice(self.reply_templates["é€šç”¨"]["neutral"])
            self._add_to_history(fallback_reply)
            return fallback_reply
    
    async def _generate_ai_reply(self, title: str, content: str, analysis: ContentAnalysis) -> Optional[str]:
        """ä½¿ç”¨AIç”Ÿæˆå›å¤ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        max_retries = 3
        base_delay = 2  # åŸºç¡€å»¶è¿Ÿ2ç§’
        
        for attempt in range(max_retries):
            try:
                # æ„å»ºç®€æ´çš„æç¤ºè¯
                prompt = self._build_short_prompt(title, content, analysis)
                
                response = await self.client.chat.completions.create(
                    model=self.config.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªçœŸå®çš„è®ºå›ç”¨æˆ·ï¼Œç”¨ç®€çŸ­è‡ªç„¶çš„è¯å›å¤å¸–å­ã€‚"
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=50,  # å¢åŠ tokenæ•°é‡ä»¥é¿å…æˆªæ–­
                    temperature=self.config.temperature,
                    top_p=0.9
                )
                
                reply = response.choices[0].message.content.strip()
                return self._clean_reply(reply)
                
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "Too Many Requests" in error_str:
                    # APIé™æµï¼Œéœ€è¦ç­‰å¾…
                    if attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                        print(f"APIé™æµï¼Œç­‰å¾… {delay} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                        await asyncio.sleep(delay)
                        continue
                    else:
                        print(f"APIé™æµï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                        return None
                else:
                    print(f"AIç”Ÿæˆå¤±è´¥: {e}")
                    return None
        
        return None
    
    def _build_short_prompt(self, title: str, content: str, analysis: ContentAnalysis) -> str:
        """æ„å»ºç®€çŸ­æç¤ºè¯ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # æˆªå–å†…å®¹ï¼Œé¿å…è¿‡é•¿
        short_content = content[:300] if content else ""
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ´»è·ƒçš„è®ºå›ç”¨æˆ·ï¼Œçœ‹åˆ°è¿™ä¸ªå¸–å­åæƒ³è¦ç®€çŸ­å›å¤ï¼š

æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{short_content}

è¯·ç”¨1-10ä¸ªå­—è‡ªç„¶å›å¤ï¼Œå°±åƒå¹³æ—¶èŠå¤©ä¸€æ ·ã€‚ç›´æ¥ç»™å‡ºå›å¤å†…å®¹ï¼š"""
        
        return prompt
    
    def _clean_reply(self, reply: str) -> str:
        """æ¸…ç†å›å¤å†…å®¹"""
        if not reply:
            return ""
            
        # ç§»é™¤å¼•å·å’Œå¤šä½™ç¬¦å·
        reply = reply.strip('"\'""''')
        
        # æ£€æŸ¥å¹¶å¤„ç†ç¼–ç é—®é¢˜
        try:
            # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„UTF-8å­—ç¬¦ä¸²
            reply = reply.encode('utf-8').decode('utf-8')
        except (UnicodeEncodeError, UnicodeDecodeError):
            # å¦‚æœæœ‰ç¼–ç é—®é¢˜ï¼Œè¿”å›é»˜è®¤å›å¤
            return "ğŸ‘"
        
        # ç§»é™¤ä¸å¯è§å­—ç¬¦å’Œæ§åˆ¶å­—ç¬¦
        import re
        reply = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', reply)
        
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«ä¸å¯æ‰“å°å­—ç¬¦
        if not reply or not any(c.isprintable() for c in reply):
            return "ğŸ‘"
        
        # ç§»é™¤ç¦ç”¨è¯
        for word in self.banned_words:
            reply = reply.replace(word, "")
        
        # é•¿åº¦æ§åˆ¶
        if len(reply) > self.config.max_length:
            reply = reply[:self.config.max_length]
        
        # ç§»é™¤å¤šä½™çš„æ ‡ç‚¹
        reply = reply.rstrip('ã€‚ï¼ï¼Ÿï¼Œã€')
        
        cleaned = reply.strip()
        
        # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè¿”å›é»˜è®¤å›å¤
        if not cleaned:
            return "ğŸ‘"
            
        return cleaned
    
    def _validate_reply(self, reply: str) -> bool:
        """éªŒè¯å›å¤è´¨é‡"""
        if not reply:
            return False
        
        # é•¿åº¦æ£€æŸ¥
        if len(reply) < self.config.min_length or len(reply) > self.config.max_length:
            return False
        
        # ç¦ç”¨è¯æ£€æŸ¥
        for word in self.banned_words:
            if word in reply:
                return False
        
        # å†…å®¹è´¨é‡æ£€æŸ¥
        if reply.isdigit():  # çº¯æ•°å­—
            return False
        
        if len(set(reply)) == 1:  # é‡å¤å­—ç¬¦
            return False
        
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ ‡ç‚¹ç¬¦å·
        if all(not c.isalnum() for c in reply):
            return False
        
        return True
    
    def _generate_template_reply(self, analysis: ContentAnalysis) -> str:
        """ç”Ÿæˆæ¨¡æ¿å›å¤ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨åˆ†ç±»æ¨¡æ¿
        category = analysis.category
        sentiment = analysis.sentiment
        
        if category in self.reply_templates:
            category_templates = self.reply_templates[category]
            if sentiment in category_templates:
                templates = category_templates[sentiment]
            else:
                # å¦‚æœæ²¡æœ‰å¯¹åº”æƒ…æ„Ÿçš„æ¨¡æ¿ï¼Œä½¿ç”¨neutral
                templates = category_templates.get("neutral", list(category_templates.values())[0])
        else:
            # ä½¿ç”¨é€šç”¨æ¨¡æ¿
            universal_templates = self.reply_templates["é€šç”¨"]
            templates = universal_templates.get(sentiment, universal_templates["neutral"])
        
        # é¿å…é‡å¤
        available_templates = [t for t in templates if not self._is_duplicate(t)]
        if not available_templates:
            available_templates = templates
        
        return random.choice(available_templates)
    
    def _is_duplicate(self, reply: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸æœ€è¿‘å›å¤é‡å¤"""
        return reply in self.recent_replies[-10:]  # æ£€æŸ¥æœ€è¿‘10ä¸ªå›å¤
    
    def _add_to_history(self, reply: str):
        """æ·»åŠ åˆ°å›å¤å†å²"""
        self.recent_replies.append(reply)
        if len(self.recent_replies) > self.max_history:
            self.recent_replies.pop(0)
    
    def get_reply_statistics(self) -> Dict[str, Any]:
        """è·å–å›å¤ç»Ÿè®¡ä¿¡æ¯"""
        if not self.recent_replies:
            return {"total": 0, "unique": 0, "diversity": 0.0}
        
        total = len(self.recent_replies)
        unique = len(set(self.recent_replies))
        diversity = unique / total if total > 0 else 0.0
        
        return {
            "total": total,
            "unique": unique,
            "diversity": diversity,
            "recent_replies": self.recent_replies[-5:]  # æœ€è¿‘5ä¸ªå›å¤
        }
    
    def clear_history(self):
        """æ¸…ç©ºå›å¤å†å²"""
        self.recent_replies.clear()


class SmartReplySelector:
    """æ™ºèƒ½å›å¤é€‰æ‹©å™¨"""
    
    def __init__(self):
        self.reply_history = []
        self.max_history = 50
    
    def select_best_reply(self, candidates: List[str], post_content: str, analysis: ContentAnalysis) -> str:
        """ä»å€™é€‰å›å¤ä¸­é€‰æ‹©æœ€ä½³å›å¤"""
        if not candidates:
            return "ğŸ‘"
        
        # è¿‡æ»¤é‡å¤å›å¤
        unique_candidates = []
        for reply in candidates:
            if reply not in self.reply_history[-10:]:  # é¿å…ä¸æœ€è¿‘10ä¸ªå›å¤é‡å¤
                unique_candidates.append(reply)
        
        if not unique_candidates:
            unique_candidates = candidates
        
        # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
        scored_replies = []
        for reply in unique_candidates:
            score = self._calculate_relevance_score(reply, post_content, analysis)
            scored_replies.append((reply, score))
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å›å¤
        best_reply = max(scored_replies, key=lambda x: x[1])[0]
        
        # è®°å½•åˆ°å†å²
        self.add_to_history(best_reply)
        
        return best_reply
    
    def _calculate_relevance_score(self, reply: str, post_content: str, analysis: ContentAnalysis) -> float:
        """è®¡ç®—å›å¤ç›¸å…³æ€§å¾—åˆ†"""
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # é•¿åº¦é€‚ä¸­åŠ åˆ†
        if 2 <= len(reply) <= 6:
            score += 0.1
        
        # åŒ…å«è¡¨æƒ…ç¬¦å·åŠ åˆ†
        if any(char in reply for char in "ğŸ‘ğŸ˜Šâ¤ï¸ğŸ’ªğŸ”¥"):
            score += 0.1
        
        # æ ¹æ®åˆ†ç±»åŒ¹é…åº¦åŠ åˆ†
        category_matches = {
            "æŠ€æœ¯è®¨è®º": ["å­¦ä¹ ", "æœ‰é“ç†", "èµåŒ", "æ”¶è—"],
            "æ±‚åŠ©é—®ç­”": ["è¯•è¯•", "æœ‰ç”¨", "åŠ æ²¹", "æ”¯æŒ"],
            "ç”Ÿæ´»åˆ†äº«": ["æœ‰æ„æ€", "èµ", "åŒæ„Ÿ", "ç¾¡æ…•"],
            "è®¨è®ºäº¤æµ": ["åŒæ„", "æ”¯æŒ", "è®¤åŒ", "æœ‰é“ç†"]
        }
        
        if analysis.category in category_matches:
            category_words = category_matches[analysis.category]
            if any(word in reply for word in category_words):
                score += 0.2
        
        # æ ¹æ®æƒ…æ„ŸåŒ¹é…åº¦åŠ åˆ†
        if analysis.sentiment == "positive" and any(word in reply for word in ["èµ", "å¥½", "æ£’", "ğŸ‘"]):
            score += 0.1
        elif analysis.sentiment == "negative" and any(word in reply for word in ["åŠ æ²¹", "æ”¯æŒ", "ç†è§£"]):
            score += 0.1
        
        return min(score, 1.0)
    
    def add_to_history(self, reply: str):
        """æ·»åŠ åˆ°å›å¤å†å²"""
        self.reply_history.append(reply)
        if len(self.reply_history) > self.max_history:
            self.reply_history.pop(0)


class ForumReplyBot:
    """è®ºå›å›å¤æœºå™¨äºº"""
    
    def __init__(self, config: ShortReplyConfig):
        self.generator = ShortReplyGenerator(config)
        self.selector = SmartReplySelector()
    
    def generate_reply_for_post(self, post_title: str, post_content: str) -> Tuple[str, ContentAnalysis]:
        """ä¸ºå¸–å­ç”Ÿæˆå›å¤"""
        # åˆ†æå¸–å­
        analysis = self.generator.content_analyzer.analyze(post_title, post_content)
        
        # ç”Ÿæˆå¤šä¸ªå€™é€‰å›å¤
        candidates = []
        
        # AIç”Ÿæˆå›å¤
        ai_reply = self.generator._generate_ai_reply(post_title, post_content, analysis)
        if ai_reply and self.generator._validate_reply(ai_reply):
            candidates.append(ai_reply)
        
        # æ¨¡æ¿å›å¤ä½œä¸ºå¤‡é€‰
        template_reply = self.generator._generate_template_reply(analysis)
        candidates.append(template_reply)
        
        # é€‰æ‹©æœ€ä½³å›å¤
        best_reply = self.selector.select_best_reply(candidates, post_content, analysis)
        
        return best_reply, analysis
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        generator_stats = self.generator.get_reply_statistics()
        
        return {
            "generator": generator_stats,
            "selector_history_size": len(self.selector.reply_history)
        }


def create_reply_bot_from_config(ai_config: AIConfig) -> ForumReplyBot:
    """ä»AIé…ç½®åˆ›å»ºå›å¤æœºå™¨äºº"""
    config = ShortReplyConfig(
        api_key=ai_config.api_key,
        base_url=ai_config.base_url,
        model=ai_config.model,
        max_length=10,  # å›ºå®šä¸º10å­—
        min_length=1,   # å›ºå®šä¸º1å­—
        temperature=ai_config.temperature,
        max_tokens=ai_config.max_tokens
    )
    
    return ForumReplyBot(config)


if __name__ == "__main__":
    # æµ‹è¯•çŸ­å›å¤ç”Ÿæˆå™¨
    from ..config.config_manager import ConfigManager
    
    config_manager = ConfigManager()
    ai_config = config_manager.get_ai_config()
    
    # åˆ›å»ºå›å¤æœºå™¨äºº
    bot = create_reply_bot_from_config(ai_config)
    
    # æµ‹è¯•å›å¤ç”Ÿæˆ
    test_posts = [
        {
            "title": "Pythonçˆ¬è™«é—®é¢˜æ±‚åŠ©",
            "content": "æˆ‘åœ¨å†™çˆ¬è™«çš„æ—¶å€™é‡åˆ°äº†åçˆ¬è™«æœºåˆ¶ï¼Œæœ‰ä»€ä¹ˆå¥½çš„è§£å†³æ–¹æ¡ˆå—ï¼Ÿ"
        },
        {
            "title": "ä»Šå¤©å¤©æ°”çœŸå¥½",
            "content": "é˜³å…‰æ˜åªšï¼Œå¿ƒæƒ…ä¹Ÿå˜å¥½äº†ï¼Œå¤§å®¶ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿ"
        },
        {
            "title": "React 19æ–°ç‰¹æ€§è®¨è®º",
            "content": "React 19æ­£å¼å‘å¸ƒï¼Œå¸¦æ¥äº†å¾ˆå¤šæ–°ç‰¹æ€§ï¼Œå¤§å®¶æ€ä¹ˆçœ‹ï¼Ÿ"
        }
    ]
    
    print("=== çŸ­å›å¤ç”Ÿæˆæµ‹è¯• ===")
    for i, post in enumerate(test_posts, 1):
        print(f"\n--- æµ‹è¯•å¸–å­ {i} ---")
        print(f"æ ‡é¢˜: {post['title']}")
        print(f"å†…å®¹: {post['content']}")
        
        reply, analysis = bot.generate_reply_for_post(post['title'], post['content'])
        print(f"ç”Ÿæˆå›å¤: {reply}")
        print(f"åˆ†æç»“æœ: {analysis.category} | {analysis.sentiment} | {analysis.confidence:.2f}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\n=== ç»Ÿè®¡ä¿¡æ¯ ===")
    stats = bot.get_statistics()
    print(f"ç”Ÿæˆå™¨ç»Ÿè®¡: {stats['generator']}")
    print(f"é€‰æ‹©å™¨å†å²: {stats['selector_history_size']}")