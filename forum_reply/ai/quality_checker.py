"""
å›å¤è´¨é‡æ£€æŸ¥å™¨
æ£€æŸ¥å›å¤çš„è´¨é‡ã€ç›¸å…³æ€§å’Œå®‰å…¨æ€§
"""

import jieba
import re
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime

from .content_analyzer import ContentAnalysis


@dataclass
class QualityScore:
    """è´¨é‡è¯„åˆ†ç»“æœ"""
    total_score: float
    component_scores: Dict[str, float]
    pass_threshold: bool
    feedback: List[str]


class QualityChecker:
    """å›å¤è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self):
        # è¿ç¦è¯åˆ—è¡¨
        self.banned_words = [
            "å¹¿å‘Š", "æ¨å¹¿", "åŠ å¾®ä¿¡", "QQç¾¤", "åˆ·å•", "ä»£åˆ·",
            "AI", "æœºå™¨äºº", "ç®—æ³•", "ç”Ÿæˆ", "è‡ªåŠ¨", "äººå·¥æ™ºèƒ½"
        ]
        
        # ä½è´¨é‡æ¨¡å¼
        self.low_quality_patterns = [
            r"^[.ã€‚]+$",  # åªæœ‰æ ‡ç‚¹
            r"^[0-9]+$",  # åªæœ‰æ•°å­—
            r"^(.)\1{2,}$",  # é‡å¤å­—ç¬¦
            r"^[a-zA-Z]+$",  # åªæœ‰è‹±æ–‡å­—æ¯
        ]
        
        # ç§¯æè¯æ±‡
        self.positive_words = [
            "èµ", "å¥½", "æ£’", "æ”¯æŒ", "ä¸é”™", "å‰å®³", "å­¦ä¹ ", "æ”¶è—",
            "æ„Ÿè°¢", "æœ‰ç”¨", "æœ‰é“ç†", "åŒæ„", "è®¤åŒ", "ç¡®å®"
        ]
        
        # è‡ªç„¶è¡¨è¾¾æ¨¡å¼
        self.natural_patterns = [
            "ğŸ‘", "ğŸ˜Š", "â¤ï¸", "ğŸ’ª", "ğŸ”¥",  # è¡¨æƒ…ç¬¦å·
            "å“ˆå“ˆ", "å—¯", "å‘€", "å•Š", "å“¦",  # è¯­æ°”è¯
            "å­¦ä¹ äº†", "æ”¶è—äº†", "è¯•è¯•çœ‹", "å¯ä»¥çš„", "æ²¡é—®é¢˜"  # è‡ªç„¶è¡¨è¾¾
        ]
    
    def check_quality(self, reply: str, post_title: str, post_content: str, 
                     analysis: ContentAnalysis) -> QualityScore:
        """æ£€æŸ¥å›å¤è´¨é‡"""
        scores = {}
        feedback = []
        
        # 1. é•¿åº¦é€‚ä¸­æ€§æ£€æŸ¥ (0-1)
        length_score, length_feedback = self._check_length(reply)
        scores['length'] = length_score
        if length_feedback:
            feedback.append(length_feedback)
        
        # 2. ç›¸å…³æ€§æ£€æŸ¥ (0-1)
        relevance_score, relevance_feedback = self._check_relevance(reply, post_title, post_content)
        scores['relevance'] = relevance_score
        if relevance_feedback:
            feedback.append(relevance_feedback)
        
        # 3. è‡ªç„¶åº¦æ£€æŸ¥ (0-1)
        naturalness_score, naturalness_feedback = self._check_naturalness(reply)
        scores['naturalness'] = naturalness_score
        if naturalness_feedback:
            feedback.append(naturalness_feedback)
        
        # 4. å®‰å…¨æ€§æ£€æŸ¥ (0-1)
        safety_score, safety_feedback = self._check_safety(reply)
        scores['safety'] = safety_score
        if safety_feedback:
            feedback.append(safety_feedback)
        
        # 5. è¡¨è¾¾æ•ˆæœæ£€æŸ¥ (0-1)
        expression_score, expression_feedback = self._check_expression(reply, analysis)
        scores['expression'] = expression_score
        if expression_feedback:
            feedback.append(expression_feedback)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆçŸ­å›å¤æƒé‡è°ƒæ•´ï¼‰
        weights = {
            'length': 0.25,      # é•¿åº¦å¾ˆé‡è¦
            'relevance': 0.20,   # ç›¸å…³æ€§é‡è¦
            'naturalness': 0.30, # è‡ªç„¶åº¦æœ€é‡è¦
            'safety': 0.15,      # å®‰å…¨æ€§
            'expression': 0.10   # è¡¨è¾¾æ•ˆæœ
        }
        
        total_score = sum(scores[key] * weights[key] for key in scores)
        pass_threshold = total_score >= 0.6  # çŸ­å›å¤é˜ˆå€¼ç¨ä½
        
        return QualityScore(
            total_score=total_score,
            component_scores=scores,
            pass_threshold=pass_threshold,
            feedback=feedback
        )
    
    def _check_length(self, reply: str) -> Tuple[float, Optional[str]]:
        """æ£€æŸ¥é•¿åº¦é€‚ä¸­æ€§"""
        length = len(reply)
        
        if 1 <= length <= 10:
            return 1.0, None
        elif length == 0:
            return 0.0, "å›å¤ä¸ºç©º"
        elif length > 10:
            return max(0, 1 - (length - 10) * 0.1), f"å›å¤è¿‡é•¿({length}å­—)"
        else:
            return 0.0, "å›å¤é•¿åº¦å¼‚å¸¸"
    
    def _check_relevance(self, reply: str, post_title: str, post_content: str) -> Tuple[float, Optional[str]]:
        """æ£€æŸ¥ç›¸å…³æ€§"""
        try:
            # æå–å¸–å­å’Œå›å¤çš„å…³é”®è¯
            post_text = f"{post_title} {post_content}"
            post_words = set(jieba.cut(post_text.lower()))
            reply_words = set(jieba.cut(reply.lower()))
            
            # ç§»é™¤åœç”¨è¯
            stop_words = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'æˆ–'}
            post_words = post_words - stop_words
            reply_words = reply_words - stop_words
            
            if not post_words or not reply_words:
                # å¦‚æœæ— æ³•æå–å…³é”®è¯ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯é€šç”¨ç§¯æå›å¤
                if any(word in reply for word in self.positive_words):
                    return 0.7, None
                return 0.5, None
            
            # è®¡ç®—å…³é”®è¯é‡å åº¦
            overlap = post_words.intersection(reply_words)
            relevance = len(overlap) / max(len(post_words), len(reply_words))
            
            # å¯¹äºçŸ­å›å¤ï¼Œé™ä½ç›¸å…³æ€§è¦æ±‚
            if len(reply) <= 5:
                relevance = max(relevance, 0.6)  # çŸ­å›å¤ç»™äºˆåŸºç¡€ç›¸å…³æ€§
            
            if relevance < 0.3:
                return relevance, "å›å¤ä¸å¸–å­å†…å®¹ç›¸å…³æ€§è¾ƒä½"
            
            return relevance, None
            
        except Exception:
            # é™çº§æ£€æŸ¥ï¼šæ˜¯å¦åŒ…å«ç§¯æè¯æ±‡
            if any(word in reply for word in self.positive_words):
                return 0.7, None
            return 0.5, None
    
    def _check_naturalness(self, reply: str) -> Tuple[float, Optional[str]]:
        """æ£€æŸ¥è‡ªç„¶åº¦"""
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # æ£€æŸ¥ä½è´¨é‡æ¨¡å¼
        for pattern in self.low_quality_patterns:
            if re.match(pattern, reply):
                return 0.1, "å›å¤æ¨¡å¼ä¸è‡ªç„¶"
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è‡ªç„¶è¡¨è¾¾
        natural_count = sum(1 for pattern in self.natural_patterns if pattern in reply)
        if natural_count > 0:
            score += 0.3
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç§¯æè¯æ±‡
        positive_count = sum(1 for word in self.positive_words if word in reply)
        if positive_count > 0:
            score += 0.2
        
        # é•¿åº¦é€‚ä¸­åŠ åˆ†
        if 2 <= len(reply) <= 8:
            score += 0.1
        
        # æ£€æŸ¥å­—ç¬¦å¤šæ ·æ€§
        if len(set(reply)) > 1:
            score += 0.1
        
        return min(score, 1.0), None
    
    def _check_safety(self, reply: str) -> Tuple[float, Optional[str]]:
        """æ£€æŸ¥å®‰å…¨æ€§"""
        # æ£€æŸ¥è¿ç¦è¯
        for word in self.banned_words:
            if word in reply:
                return 0.0, f"åŒ…å«è¿ç¦è¯: {word}"
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿå†…å®¹
        sensitive_patterns = [
            r"å¾®ä¿¡", r"QQ", r"ç¾¤", r"åŠ æˆ‘", r"è”ç³»",
            r"å¹¿å‘Š", r"æ¨å¹¿", r"è¥é”€", r"ä»£ç†"
        ]
        
        for pattern in sensitive_patterns:
            if re.search(pattern, reply):
                return 0.3, f"å¯èƒ½åŒ…å«æ•æ„Ÿå†…å®¹: {pattern}"
        
        return 1.0, None
    
    def _check_expression(self, reply: str, analysis: ContentAnalysis) -> Tuple[float, Optional[str]]:
        """æ£€æŸ¥è¡¨è¾¾æ•ˆæœ"""
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # è¡¨æƒ…ç¬¦å·åŠ åˆ†
        emoji_count = sum(1 for char in reply if char in "ğŸ‘ğŸ˜Šâ¤ï¸ğŸ’ªğŸ”¥ğŸ¤”ğŸ˜…")
        if emoji_count > 0:
            score += 0.3
        
        # æ ¹æ®å¸–å­åˆ†ç±»æ£€æŸ¥è¡¨è¾¾é€‚é…æ€§
        category_expressions = {
            "æŠ€æœ¯è®¨è®º": ["å­¦ä¹ ", "æœ‰é“ç†", "èµåŒ", "æ”¶è—", "ğŸ‘"],
            "æ±‚åŠ©é—®ç­”": ["è¯•è¯•", "æœ‰ç”¨", "åŠ æ²¹", "æ”¯æŒ", "å¯ä»¥"],
            "ç”Ÿæ´»åˆ†äº«": ["æœ‰æ„æ€", "èµ", "åŒæ„Ÿ", "ç¾¡æ…•", "ğŸ˜Š"],
            "è®¨è®ºäº¤æµ": ["åŒæ„", "æ”¯æŒ", "è®¤åŒ", "æœ‰é“ç†", "ğŸ‘"]
        }
        
        if analysis.category in category_expressions:
            expressions = category_expressions[analysis.category]
            if any(expr in reply for expr in expressions):
                score += 0.2
        
        # æƒ…æ„ŸåŒ¹é…æ£€æŸ¥
        if analysis.sentiment == "positive" and any(word in reply for word in ["èµ", "å¥½", "æ£’", "ğŸ‘"]):
            score += 0.1
        elif analysis.sentiment == "negative" and any(word in reply for word in ["åŠ æ²¹", "æ”¯æŒ", "ç†è§£"]):
            score += 0.1
        
        return min(score, 1.0), None
    
    def batch_check_quality(self, replies: List[Tuple[str, str, str, ContentAnalysis]]) -> List[QualityScore]:
        """æ‰¹é‡æ£€æŸ¥å›å¤è´¨é‡"""
        results = []
        
        for reply, post_title, post_content, analysis in replies:
            quality_score = self.check_quality(reply, post_title, post_content, analysis)
            results.append(quality_score)
        
        return results
    
    def get_quality_statistics(self, quality_scores: List[QualityScore]) -> Dict[str, Any]:
        """è·å–è´¨é‡ç»Ÿè®¡ä¿¡æ¯"""
        if not quality_scores:
            return {}
        
        total_count = len(quality_scores)
        passed_count = sum(1 for score in quality_scores if score.pass_threshold)
        
        # è®¡ç®—å„é¡¹å¹³å‡åˆ†
        avg_scores = {}
        for component in ['length', 'relevance', 'naturalness', 'safety', 'expression']:
            avg_scores[component] = sum(
                score.component_scores.get(component, 0) for score in quality_scores
            ) / total_count
        
        avg_total = sum(score.total_score for score in quality_scores) / total_count
        
        return {
            'total_count': total_count,
            'passed_count': passed_count,
            'pass_rate': passed_count / total_count,
            'average_total_score': avg_total,
            'average_component_scores': avg_scores,
            'quality_distribution': {
                'excellent': sum(1 for s in quality_scores if s.total_score >= 0.8),
                'good': sum(1 for s in quality_scores if 0.6 <= s.total_score < 0.8),
                'poor': sum(1 for s in quality_scores if s.total_score < 0.6)
            }
        }


class AdaptiveQualityChecker(QualityChecker):
    """è‡ªé€‚åº”è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self):
        super().__init__()
        self.quality_history = []
        self.max_history = 100
        self.threshold_adjustment = 0.0
    
    def check_quality_adaptive(self, reply: str, post_title: str, post_content: str, 
                              analysis: ContentAnalysis) -> QualityScore:
        """è‡ªé€‚åº”è´¨é‡æ£€æŸ¥"""
        # åŸºç¡€è´¨é‡æ£€æŸ¥
        quality_score = self.check_quality(reply, post_title, post_content, analysis)
        
        # è®°å½•å†å²
        self.quality_history.append(quality_score.total_score)
        if len(self.quality_history) > self.max_history:
            self.quality_history.pop(0)
        
        # è‡ªé€‚åº”è°ƒæ•´é˜ˆå€¼
        self._adjust_threshold()
        
        # é‡æ–°è®¡ç®—æ˜¯å¦é€šè¿‡
        adjusted_threshold = 0.6 + self.threshold_adjustment
        quality_score.pass_threshold = quality_score.total_score >= adjusted_threshold
        
        return quality_score
    
    def _adjust_threshold(self):
        """æ ¹æ®å†å²è´¨é‡è°ƒæ•´é˜ˆå€¼"""
        if len(self.quality_history) < 10:
            return
        
        recent_avg = sum(self.quality_history[-10:]) / 10
        overall_avg = sum(self.quality_history) / len(self.quality_history)
        
        # å¦‚æœæœ€è¿‘è´¨é‡ä¸‹é™ï¼Œé™ä½é˜ˆå€¼
        if recent_avg < overall_avg - 0.1:
            self.threshold_adjustment = max(self.threshold_adjustment - 0.05, -0.2)
        # å¦‚æœæœ€è¿‘è´¨é‡æå‡ï¼Œæé«˜é˜ˆå€¼
        elif recent_avg > overall_avg + 0.1:
            self.threshold_adjustment = min(self.threshold_adjustment + 0.05, 0.2)
    
    def get_adaptive_stats(self) -> Dict[str, Any]:
        """è·å–è‡ªé€‚åº”ç»Ÿè®¡ä¿¡æ¯"""
        if not self.quality_history:
            return {}
        
        return {
            'history_count': len(self.quality_history),
            'recent_average': sum(self.quality_history[-10:]) / min(10, len(self.quality_history)),
            'overall_average': sum(self.quality_history) / len(self.quality_history),
            'threshold_adjustment': self.threshold_adjustment,
            'current_threshold': 0.6 + self.threshold_adjustment
        }


if __name__ == "__main__":
    # æµ‹è¯•è´¨é‡æ£€æŸ¥å™¨
    from .content_analyzer import ContentAnalyzer
    
    analyzer = ContentAnalyzer()
    checker = QualityChecker()
    
    # æµ‹è¯•æ•°æ®
    test_cases = [
        {
            "reply": "ğŸ‘",
            "title": "Pythonå­¦ä¹ å¿ƒå¾—",
            "content": "æœ€è¿‘åœ¨å­¦Pythonï¼Œæ„Ÿè§‰å¾ˆæœ‰æ„æ€"
        },
        {
            "reply": "å­¦ä¹ äº†",
            "title": "Reactæ–°ç‰¹æ€§ä»‹ç»",
            "content": "React 19å¸¦æ¥äº†å¾ˆå¤šæ–°åŠŸèƒ½"
        },
        {
            "reply": "å¹¿å‘Šæ¨å¹¿åŠ å¾®ä¿¡",
            "title": "æŠ€æœ¯è®¨è®º",
            "content": "è®¨è®ºä¸€ä¸‹æ–°æŠ€æœ¯"
        },
        {
            "reply": "aaaaaaa",
            "title": "æ±‚åŠ©å¸–",
            "content": "é‡åˆ°äº†é—®é¢˜"
        },
        {
            "reply": "æœ‰é“ç†ï¼Œæ”¯æŒ",
            "title": "è§‚ç‚¹åˆ†äº«",
            "content": "æˆ‘è§‰å¾—è¿™ä¸ªæƒ³æ³•å¾ˆå¥½"
        }
    ]
    
    print("=== è´¨é‡æ£€æŸ¥æµ‹è¯• ===")
    for i, case in enumerate(test_cases, 1):
        print(f"\n--- æµ‹è¯•æ¡ˆä¾‹ {i} ---")
        print(f"å›å¤: {case['reply']}")
        print(f"å¸–å­: {case['title']}")
        
        # åˆ†æå¸–å­å†…å®¹
        analysis = analyzer.analyze(case['title'], case['content'])
        
        # æ£€æŸ¥è´¨é‡
        quality = checker.check_quality(
            case['reply'], case['title'], case['content'], analysis
        )
        
        print(f"æ€»åˆ†: {quality.total_score:.2f}")
        print(f"é€šè¿‡: {'âœ“' if quality.pass_threshold else 'âœ—'}")
        print(f"å„é¡¹å¾—åˆ†: {quality.component_scores}")
        if quality.feedback:
            print(f"åé¦ˆ: {quality.feedback}")
    
    # æµ‹è¯•è‡ªé€‚åº”æ£€æŸ¥å™¨
    print(f"\n=== è‡ªé€‚åº”è´¨é‡æ£€æŸ¥æµ‹è¯• ===")
    adaptive_checker = AdaptiveQualityChecker()
    
    for case in test_cases:
        analysis = analyzer.analyze(case['title'], case['content'])
        quality = adaptive_checker.check_quality_adaptive(
            case['reply'], case['title'], case['content'], analysis
        )
        print(f"å›å¤: {case['reply']} | å¾—åˆ†: {quality.total_score:.2f} | é€šè¿‡: {'âœ“' if quality.pass_threshold else 'âœ—'}")
    
    print(f"\nè‡ªé€‚åº”ç»Ÿè®¡: {adaptive_checker.get_adaptive_stats()}")